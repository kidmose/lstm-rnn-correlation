{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Copyright (C) Egon Kidmose 2015-2017\n",
    "\n",
    "This file is part of lstm-rnn-correlation.\n",
    "\n",
    "lstm-rnn-correlation is free software: you can redistribute it and/or\n",
    "modify it under the terms of the GNU Lesser General Public License as\n",
    "published by the Free Software Foundation, either version 3 of the\n",
    "License, or (at your option) any later version.\n",
    "\n",
    "lstm-rnn-correlation is distributed in the hope that it will be\n",
    "useful, but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n",
    "Lesser General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Lesser General Public\n",
    "License along with lstm-rnn-correlation. If not, see\n",
    "<http://www.gnu.org/licenses/>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import ipaddress\n",
    "\n",
    "# matplotlib\n",
    "try: # might, might not have x available\n",
    "    import os\n",
    "    os.environ['DISPLAY']\n",
    "except KeyError:\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "try: # might, might not be notebook\n",
    "    %matplotlib inline\n",
    "except NameError:\n",
    "    pass\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 1468586473 # Unix time at time of writing\n",
    "def rndseed():\n",
    "    global seed\n",
    "    seed += 1\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_cfg import data\n",
    "# load files\n",
    "data_tmp = DataFrame()\n",
    "for index, row in data.iterrows():\n",
    "    print(\"Opening: {}\".format(row['filename']))\n",
    "    with open(row['filename']) as f:\n",
    "        alerts = DataFrame(\n",
    "            map(parse_line, f.readlines()),\n",
    "            columns=['ts', 'rid', 'msg', 'prio', 'proto', 'srcip', 'srcport', 'dstip', 'dstport']\n",
    "        )\n",
    "        alerts['incident'] = row['incident']   \n",
    "        data_tmp = data_tmp.append(pd.merge(data, alerts))\n",
    "        print(\"Loaded: {}\".format(row['filename']))\n",
    "data = data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difficult_ips = [\n",
    "    '94.63.149.152',\n",
    "    '147.32.84.165',\n",
    "]\n",
    "for ip in difficult_ips:\n",
    "    assert re.match('('+IP+')', ip).group()\n",
    "\n",
    "difficult_ips_port = [\n",
    "    '94.63.149.152:80',\n",
    "    '147.32.84.165:1040',\n",
    "]\n",
    "for ip in difficult_ips_port:\n",
    "    res = re.match(IP_PORT, ip).groups()\n",
    "    assert res is not None\n",
    "    assert len(res) == 2\n",
    "\n",
    "difficult_lines = [\n",
    "    '08/15-15:53:48.900440  [**] [120:3:1] (http_inspect) NO CONTENT-LENGTH OR TRANSFER-ENCODING IN HTTP RESPONSE [**] [Classification: Unknown Traffic] [Priority: 3] {TCP} 94.63.149.152:80 -> 147.32.84.165:1040\\n',\n",
    "]\n",
    "for l in difficult_lines:\n",
    "    res = parse_line(l)\n",
    "    assert len(res) == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IPV4 = '(?:[0-9]{1,3}(?:\\.[0-9]{1,3}){3})'\n",
    "IPV6 = '(?:[0-9a-f]|:){1,4}(?::(?:[0-9a-f]{0,4})*){1,7}'\n",
    "IP = '(?:{}|{})'.format(IPV4, IPV6)\n",
    "IP_PORT = '('+IP+')(?::([^ ]+))?'\n",
    "\n",
    "SNORT_REGEX = re.compile('^(.*)  \\[\\*\\*] \\[([^]]*)] (.*) \\[Priority: ([0-9])] {([^}]*)} ('+IP+')(?::([^ ]+))? -> ('+IP+')(?::([^ ]+))?\\n')\n",
    "SNORT_TS_FMT = '%m/%d/%y-%H:%M:%S.%f'\n",
    "SNORT_TS_FMT_NO_YR = '%m/%d-%H:%M:%S.%f'\n",
    "\n",
    "def strptime(string):\n",
    "    ts = None\n",
    "    try:\n",
    "        ts = datetime.datetime.strptime(string, SNORT_TS_FMT)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ts = datetime.datetime.strptime(string, SNORT_TS_FMT_NO_YR)\n",
    "    except:\n",
    "        pass\n",
    "    if ts is None:\n",
    "        raise Exception('Failed to parse {}: {}'.format(type(string), string))\n",
    "    return ts\n",
    "\n",
    "def strftime(ts):\n",
    "    return ts.strftime(SNORT_TS_FMT)\n",
    "\n",
    "def parse_line(line):\n",
    "    tupl = re.match(SNORT_REGEX, line).groups()\n",
    "    tupl = tuple([strptime(tupl[0])]) + tupl[1:]\n",
    "    return tupl\n",
    "\n",
    "\n",
    "def build_line(tupl):\n",
    "    tupl = tuple([strftime(tupl[0])]) + tupl[1:]\n",
    "    return \"{}  [**] [{}] {} [Priority: {}] {{{}}} {} -> {}\\n\".format(*tupl)\n",
    "\n",
    "test_code =\\\n",
    "\"\"\"\n",
    "for fn in data['filename']:\n",
    "    for l in open(fn).readlines():\n",
    "        p = parse_line(l)\n",
    "        b = build_line(p)\n",
    "        assert l == b or l == (b[:5]+b[8:]), \"Mismatch in result\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data overview\n",
    "# by incident\n",
    "def get_data_overview(data):\n",
    "    df_inc_cnt = DataFrame(data.groupby(['incident']).size().rename('inc_cnt').reset_index())\n",
    "    df_inc_cnt['inc_cnt_pct'] = df_inc_cnt['inc_cnt']/data.count()[0]*100\n",
    "\n",
    "    df_inc_prio_cnt = DataFrame(\n",
    "        pd.merge(data, df_inc_cnt, on='incident').groupby(['incident', 'prio', 'inc_cnt']\n",
    "    ).size().rename('inc_prio_cnt').reset_index())\n",
    "    df_inc_prio_cnt['inc_prio_cnt_pct'] = df_inc_prio_cnt['inc_prio_cnt']/df_inc_prio_cnt['inc_cnt']*100\n",
    "\n",
    "    df_overview = pd.merge(df_inc_cnt, df_inc_prio_cnt).groupby(['incident', 'prio']).first().reset_index()\n",
    "\n",
    "    tot_prio = data.groupby(['prio']).size().rename('inc_prio_cnt')\n",
    "    df_tot = DataFrame(tot_prio)\n",
    "    df_tot['inc_prio_cnt_pct'] = df_tot['inc_prio_cnt']/data.count()[0]*100\n",
    "    df_tot['inc_cnt'] = data.count()[0]\n",
    "    df_tot['inc_cnt_pct'] = 100\n",
    "    df_tot['incident'] = 'total'\n",
    "\n",
    "    df_overview = pd.concat([df_overview.reset_index(), df_tot.reset_index()])\\\n",
    "        .groupby(['incident', 'inc_cnt', 'inc_cnt_pct', 'prio', 'inc_prio_cnt', 'inc_prio_cnt_pct', ])\\\n",
    "        .first().drop('index', 1)\n",
    "\n",
    "    return df_overview\n",
    "\n",
    "df_overview = get_data_overview(data)\n",
    "df_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print in latex friendly\n",
    "for l in np.concatenate([\n",
    "    np.array([df_overview.reset_index().columns]),\n",
    "    df_overview.reset_index().as_matrix(),\n",
    "]):\n",
    "    print(('\\t&'.join(['{}']*len(l)) + '\\\\\\\\\\\\hline').format(*l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data time overview\n",
    "df_ts = data[['incident', 'ts']].groupby('incident').agg(['min', 'max'])['ts']\n",
    "df_ts.columns = ['start', 'stop', ]\n",
    "df_ts['dur'] = df_ts['stop']-df_ts['start']\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = None\n",
    "ax = None\n",
    "def time_span_plot(dataframe):\n",
    "    \"Dataframe must have 'start' and 'duration' keys\"\n",
    "    global fig, ax\n",
    "    fig, ax = plt.subplots()\n",
    "    for index, row in dataframe.iterrows():\n",
    "        x = row['start'] + row['dur']/2\n",
    "        y = int(index) if index is not 'benign' else 0\n",
    "        xerr = row['dur']/2\n",
    "        ax.errorbar(x, y, xerr=xerr)\n",
    "    \n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    ax.set_ylim(np.array(ax.get_ylim()) + [-1, 1])\n",
    "    \n",
    "    fig.set_size_inches(14, 2)\n",
    "\n",
    "time_span_plot(df_ts[(df_ts.index == 'benign')])\n",
    "time_span_plot(df_ts[(df_ts.index != 'benign')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate random shift to end up within boundaries of benign\n",
    "new_start_min = df_ts.loc['benign']['start']\n",
    "new_start_max = df_ts.loc['benign']['stop']-df_ts['dur']\n",
    "window = new_start_max - new_start_min\n",
    "assert (np.array(\n",
    "        window+df_ts['dur']-df_ts.loc['benign']['dur'],\n",
    "        dtype='object') == 0).all(), \"window is wrong\"\n",
    "\n",
    "np.random.seed(rndseed())\n",
    "df_ts['shift'] = new_start_min - df_ts['start'] \\\n",
    "    + map(lambda delta : np.random.rand()*delta, window)\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply shift\n",
    "shifted_data = pd.merge(data, df_ts.reset_index(), on='incident')\n",
    "shifted_data['ts'] = shifted_data['ts'] + shifted_data['shift']\n",
    "assert shifted_data['ts'].max() == data.groupby(['incident']).max().loc['benign']['ts']\n",
    "assert shifted_data['ts'].min() == data.groupby(['incident']).min().loc['benign']['ts']\n",
    "data = shifted_data\n",
    "data = data.sort_values('ts')\n",
    "data = data[data_tmp.columns] # only original columns\n",
    "\n",
    "df_ts = data[['incident', 'ts']].groupby('incident').agg(['min', 'max'])['ts']\n",
    "df_ts.columns = ['start', 'stop', ]\n",
    "df_ts['dur'] = df_ts['stop']-df_ts['start']\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_span_plot(df_ts)\n",
    "ax.plot(new_start_min, 0, 'og')\n",
    "ax.plot(new_start_max[:-1], range(1, len(new_start_max)), 'or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rewrite victim IPs to match benign\n",
    "malicious_ips = data[data['victim_ip'] != 'benign']\\\n",
    "    [['incident', 'victim_ip']].drop_duplicates()\n",
    "\n",
    "data_benign = data[data['incident'] == 'benign']\n",
    "benign_ips = pd.Series(pd.concat([data_benign['srcip'],data_benign['dstip']]).unique(), name='benign_ips')\n",
    "def is_private_ip(string):\n",
    "    try:\n",
    "        return ipaddress.IPv4Address(string).is_private\n",
    "    except ipaddress.AddressValueError:\n",
    "        print(\"ignoring IPv6 addres: {}\".format(string))\n",
    "        return False\n",
    "    \n",
    "benign_ips = benign_ips[np.array(map(is_private_ip, benign_ips))] # only private\n",
    "benign_ips = benign_ips.sample(malicious_ips.shape[0], random_state=rndseed())\n",
    "df_replace = DataFrame(\n",
    "    zip(malicious_ips['incident'], malicious_ips['victim_ip'], benign_ips),\n",
    "    columns=['incident', 'from_ip', 'to_ip']\n",
    ")\n",
    "df_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform IP replacement\n",
    "src_update = pd.merge(data.reset_index(), df_replace, left_on=['incident', 'srcip'], right_on=['incident', 'from_ip'])\n",
    "src_update['srcip'] = src_update['to_ip']\n",
    "src_update = src_update.drop(['from_ip', 'to_ip'], axis=1)\n",
    "src_update = src_update.set_index('index')\n",
    "data.update(src_update)\n",
    "\n",
    "dst_update = pd.merge(data.reset_index(), df_replace, left_on=['incident', 'dstip'], right_on=['incident', 'from_ip'])\n",
    "dst_update['dstip'] = dst_update['to_ip']\n",
    "dst_update = dst_update.drop(['from_ip', 'to_ip'], axis=1)\n",
    "dst_update = dst_update.set_index('index')\n",
    "data.update(dst_update)\n",
    "\n",
    "assert (np.array(src_update.groupby('incident').size()) > 0).all(), \"No src updated, highly suspicous\"\n",
    "assert (np.array(dst_update.groupby('incident').size()) > 0).all(), \"No dst updated, highly suspicous\"\n",
    "assert pd.merge(data, df_replace, left_on=['incident', 'srcip'], right_on=['incident', 'from_ip']).shape[0] == 0\n",
    "assert pd.merge(data, df_replace, left_on=['incident', 'dstip'], right_on=['incident', 'from_ip']).shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_data_overview(data[:data.shape[0]//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_data_overview(data[data.shape[0]//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
