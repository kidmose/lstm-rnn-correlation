{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Egon Kidmose 2015-2017\n",
    "\n",
    "This file is part of lstm-rnn-correlation.\n",
    "\n",
    "lstm-rnn-correlation is free software: you can redistribute it and/or\n",
    "modify it under the terms of the GNU Lesser General Public License as\n",
    "published by the Free Software Foundation, either version 3 of the\n",
    "License, or (at your option) any later version.\n",
    "\n",
    "lstm-rnn-correlation is distributed in the hope that it will be\n",
    "useful, but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n",
    "Lesser General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Lesser General Public\n",
    "License along with lstm-rnn-correlation. If not, see\n",
    "<http://www.gnu.org/licenses/>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning how to tie weights together\n",
    "The purpose of this notebook is to learn/demonstrate how the weights of two layers can be tied together, such that the weights are always the same.\n",
    "\n",
    "         IN\n",
    "       /    \\ \n",
    "     L1      L2\n",
    "     |        |\n",
    "    OUT1  == OUT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    def get_xors(n):\n",
    "        inputs = np.random.randint(0, 2, (n, 2)).astype(bool)\n",
    "        return inputs, inputs[:,0]^inputs[:,1]\n",
    "    \n",
    "    X_train, y_train = get_xors(1000)\n",
    "    X_val, y_val = get_xors(1000)\n",
    "    X_test, y_test = get_xors(1000)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "input_var = T.imatrix('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create training network\n",
    "net = InputLayer(shape=(None, 2), input_var=input_var, name='INPUT-LAYER')\n",
    "net = DenseLayer(net, num_units=3, nonlinearity=sigmoid, name='SIGMOID-LAYER')\n",
    "net = DenseLayer(net, num_units=2, nonlinearity=softmax, name='OUTPUT-LAYER')\n",
    "\n",
    "# Create an identical test network, with tied weights\n",
    "test_net = InputLayer(shape=(None, 2), input_var=input_var, name='TEST-INPUT-LAYER')\n",
    "for l in lasagne.layers.get_all_layers(net):\n",
    "    print(\"{} ({}):\".format(l.name, l))\n",
    "    if isinstance(l, InputLayer):\n",
    "        print(' - skipping')\n",
    "    elif isinstance(l, DenseLayer):\n",
    "        test_net = DenseLayer(\n",
    "            test_net, num_units=l.num_units, nonlinearity=l.nonlinearity, name='TEST-'+l.name, \n",
    "            W=l.W, l.b=b,\n",
    "        )\n",
    "        print(' - added layer: {} ({})'.format(get_all_layers(test_net)[-1], get_all_layers(test_net)[-1].name))\n",
    "    else:\n",
    "        raise ValueError(\"Unhandled layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "prediction = lasagne.layers.get_output(net)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "params = lasagne.layers.get_all_params(net, trainable=True)\n",
    "updates = lasagne.updates.sgd(loss, params, learning_rate=0.1)\n",
    "\n",
    "# Testing\n",
    "test_prediction = lasagne.layers.get_output(test_net, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 100, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 100, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    \"\"\"print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\"\"\"\n",
    "\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 100, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=1) \n",
    "print('trained network paramters:')\n",
    "for l in get_all_layers(net):\n",
    "    print(l)\n",
    "    print(' {}'.format(l.name))\n",
    "    for p in l.get_params():\n",
    "        print(' {}'.format(p))\n",
    "        print('  {}'.format(p.get_value()))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print('test network paramters:')\n",
    "for l in get_all_layers(test_net):\n",
    "    print(l)\n",
    "    print(' {}'.format(l.name))\n",
    "    for p in l.get_params():\n",
    "        print(' {}'.format(p))\n",
    "        print('  {}'.format(p.get_value()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
